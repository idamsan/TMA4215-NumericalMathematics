{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMA4215 Numerisk Matematikk \n",
    "\n",
    "Autumn 2021 – August 27, 2021\n",
    "\n",
    "Problems created and reviewed by: R. Bergmann, E. Çokaj, O. P. Hellan \n",
    "\n",
    "Problems answered by: I. M. Sandum\n",
    "\n",
    "# Problem Sheet 1\n",
    "\n",
    "## Deadline\n",
    "September 5, 2021, 23:59\n",
    "\n",
    "\n",
    "## Submission\n",
    "submit your Jupyter notebook containing the solution via upload in blackboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.\n",
    "\n",
    "Let $A\\in \\mathbb R^{n\\times n}$ be an invertible matrix and $b\\in\\mathbb R^n$ be given.\n",
    "    Consider the problem of solving the linear system of equations “Find $x\\in \\mathbb R^n$ such that $Ax=b$”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose we find $x$ with an error $\\delta x$ due to an error in $b$ of size $\\delta b$. This means we actually solved\n",
    "   $$ A(x+\\delta x) = b + \\delta b$$\n",
    "   Derive upper bounds for the absolute condition number $\\frac{\\lVert \\delta x \\rVert}{\\lVert\\delta b\\rVert} \\leq K_{\\mathrm{abs}}(b)$\n",
    "   and the relative condition number $\\frac{\\lVert\\delta x \\rVert / \\lVert x\\rVert}{\\lVert \\delta b\\rVert / \\lVert b \\rVert } \\leq K(b)$ for the case of the $2$-norm in terms of the Eigenvalues of $A$.\n",
    "\n",
    "   Main ingredients are the $2$-norm of a vector, the (compatible, induced) $2$-norm (or spectral norm) of a matrix and their compatibility, i.e. that $\\lVert Ax\\rVert_2 \\leq \\lVert A\\rVert_2 \\lVert x\\rVert_2$ holds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let further $A$ be disturbed data, i. e. we have a disturbed solution $x+\\delta x$ often\n",
    "   $$\n",
    "   (A+\\delta A)(x+\\delta x) = b+\\delta b\n",
    "   $$\n",
    "   How does the relative error $\\frac{\\lVert \\delta x \\rVert}{\\lVert x \\rVert}$ depend on the two relative errors $\\frac{\\lVert \\delta b \\rVert}{\\lVert b \\rVert}$ and $\\frac{\\lVert \\delta A \\rVert}{\\lVert a \\rVert}$ of the data?\n",
    "\n",
    "3. What can you say **a priori** (before you solve any system) about relative errors when\n",
    "$$\n",
    "  Ax = \\begin{pmatrix}\n",
    "  1 & 1\\\\\n",
    "  1.0004 & 1\n",
    "  \\end{pmatrix}x\n",
    "  = \\begin{pmatrix}\n",
    "    2\\\\2\n",
    "  \\end{pmatrix} = b\n",
    "$$\n",
    "  is given (you can use Python to reason for your answer)?\n",
    "  Compute the exact solution by hand and use `Python` to solve the disturbed version with $\\delta b = \\begin{pmatrix} 2\\\\2.001 \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. eq. 2.7 in the book gives $K_{rel}(b)\\approx ||G'(b)|| \\frac{||b||}{||G(b)||} = \\frac{||A^{-1}||\\cdot||b||}{||A^{-1}b||}=\\frac{||A^{-1}||\\cdot||Ax||}{||x||}\\leq ||A^{-1}||\\cdot||A|| = K(A)$ (eq. 3.4), where the less than or equal part comes from eq 1.19. Furthermore, eq. 3.5 gives $K_2(A)=\\frac{\\lambda_{max}}{\\lambda_{min}}$\n",
    "\n",
    "    2.7 also gives $K_{abs}(b)\\approx||G'(b)||=||A^{-1}||=\\frac{K_2(A)}{||A_2||}=\\frac{\\lambda_{max}/\\lambda_{min}}{\\lambda_{max}}=\\frac{1}{\\lambda_{min}}$\n",
    "    \n",
    "2. According to eq. 3.9 in the book, we have that $\\frac{||\\delta x||}{||x||}\\leq\\frac{K(A)}{1-K(A)||\\delta A||/||A||}(\\frac{||\\delta b||}{||b||}+\\frac{||\\delta A||}{||A||})$, so the two relative errors of the data creates an upper bound of sorts.\n",
    "\n",
    "\n",
    "3. If we calculate the condition number, we can know in advance if the relative error is going to be big or small. For example, the condition number for this matrix A (calculated below) is $\\approx 10002$, which is very high. I can therefore expect a big error for the disturbed version. From the calculations below I can confirm that the perturbed solution is quite wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number for A:  10002.000300008634\n",
      "The exact solution is  [0. 2.]\n",
      "The perturbed solution is  [ 2.5 -0.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A=np.matrix([[1,1],[1.0004,1]])\n",
    "print(\"Condition number for A: \", np.linalg.cond(A))\n",
    "\n",
    "b=np.array([2,2])\n",
    "print(\"The exact solution is \" , np.linalg.solve(A,b))\n",
    "\n",
    "db=np.array([2,2.001])\n",
    "diffx=np.array([0,0.001])\n",
    "print(\"The perturbed solution is \", np.linalg.solve(A,db))\n",
    "#print(np.linalg.norm(np.linalg.solve(A,b))/np.linalg.norm(np.linalg.solve(A,db)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the LU factorisation with pivoting of a matrix $A$\n",
    "\n",
    "$$\n",
    "     PA = LU\n",
    "$$\n",
    "\n",
    "where $P$ is a permutation matrix, $L$ is a lower-triangular matrix with unit diagonal, and $U$ is an upper-triangular matrix.\n",
    "We represent the matrices in question as follows:\n",
    "The permutation matrix $P$ is $n\\times n$, but is represented as a vector $\\mathtt{P}$ such that row number $k$ in $P$ is the canonical unit vector $e_{\\mathtt{P}_k}$. Let us illustrate this by an example\n",
    "\n",
    "$$\n",
    "\\mathtt{P}=\n",
    "\\left[\n",
    "\\begin{array}{r} 3 \\\\ 1 \\\\ 2 \\end{array}\n",
    "\\right]\\quad\\Rightarrow\\quad\n",
    "P=\\left[\n",
    "\\begin{array}{ccc}\n",
    "0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "We stipulate that a Python function takes a two-dimensional numpy-array $\\mathtt{A}$ as input, and returns\n",
    "an *over-written* $\\mathtt{A}$ which contains $L$ and $U$ in the following sense upon return:\n",
    "x\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\mathtt{A}[\\mathtt{P}[i],j] = L_{ij} & \\text{for}\\ i<j \\\\\n",
    "\\mathtt{A}[\\mathtt{P}[i],j] = U_{ij} & \\text{for}\\ i\\geq j\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That $L$ has 1 on the diagonal is always the case, so the diagonal of $L$ needs not be stored. The remaining elements of $L$ and $U$ are zero and need not be stored either. The algorithm can be formulated as follows (compare to text book):\n",
    "\n",
    "- Input: $A$ of size $n\\times n$\n",
    "- Initialisation\n",
    "    * Let $P_i = i,\\ i=0,\\ldots,n-1$ be a vector (array) with $n$ components\n",
    "- for $k$ **in** range(n-1):\n",
    "    1. Find index $P_\\ell$ such that $|\\mathtt{A}_{P_\\ell,k}|=\\max_{k\\leq i \\leq n-1} |\\mathtt{A}_{P_i,k}|$, i.e. scan column $k$ from the diagonal and down for the largest element in absolute value. \n",
    "    2. Swap $P_k$ by $P_\\ell$.\n",
    "    3. Find multipliers $A_{P_i,k}\\leftarrow \\frac{A_{P_i,k}}{A_{P_k,k}},\\ i=k+1,\\ldots,n-1$.\n",
    "    4. Perform elimination, i.e. $A_{P_i,j}\\leftarrow A_{P_i,j}-A_{P_i,k}\\cdot A_{P_k,j},\\ i,j=k+1,\\ldots,n-1$\n",
    "- Output: A,P\n",
    "\n",
    "There are – of course – implementations of these, often highly optimised for special cases (e.g. when $A$ is sparse) but here we first want to learn how to code it ourselves. Let's also use this to our advantage\n",
    "\n",
    "\n",
    "1. Write a function for LU-factorisation with row-wise pivoting as indicated above.\n",
    "   A template could be\n",
    "\n",
    "       def mylu(A):\n",
    "   \n",
    "    \n",
    "   and it should return the pivot vector (permutation vector) $\\mathtt{P}$, and over-written  version of $A$. You can also choose to copy $A$ into some other matrix $\\mathtt{LU}$ from the beginning using e.g. \n",
    "\n",
    "       LU = A.copy()\n",
    "\n",
    "2. use the function `scipy.linalg.lu` to test your implementation from the first part. Write a test function\n",
    "\n",
    "       def mylutest(A)\n",
    "   \n",
    "   that compares the result of your implementation to the one from `SciPy`. Call this function for example with\n",
    "\n",
    "   $$\n",
    "   A = \\begin{pmatrix} 2 & 5 & 8 & 7\\\\ 5 & 2 & 2 & 8 \\\\ 7 & 5 & 6 & 6\\\\ 5 & 4 & 4 & 8\\end{pmatrix}\n",
    "   $$\n",
    "   \n",
    "   (or `np.array([[2, 5, 8, 7], [5, 2, 2, 8], [7, 5, 6, 6], [5, 4, 4, 8]])` to easier copy it).\n",
    "   \n",
    "3. Test your function with a matrix `A` that does not meet our assumption of having full rank, for example by repeating a column. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import lu\n",
    "\n",
    "def myLu(A): #A nxn array\n",
    "    A_new = np.copy(A)\n",
    "    P=np.arange(A.shape[0],dtype=int)\n",
    "    \n",
    "    for k in range(0,A.shape[0]-1):  #every column \n",
    "        M = -1 #need this one to reset for every column \n",
    "        ind_row = -1 #same, index row\n",
    "        for i in range(k,A.shape[0]): #every row from diagonal and down\n",
    "            if (abs(A[P[i],k]) > M):\n",
    "                M = abs(A[P[i],k])\n",
    "                ind_row = i\n",
    "        temp = P[k]\n",
    "        P[k] = P[ind_row]\n",
    "        P[ind_row] = temp\n",
    "        for i in range(k+1,A.shape[0]):\n",
    "            A_new[P[i],k]=A_new[P[i],k]/A_new[P[k],k]\n",
    "        for i in range(k+1,A.shape[0]):\n",
    "            for j in range(k+1, A.shape[0]):\n",
    "                A_new[P[i],j]=A_new[P[i],j]-A_new[P[i],k]*A_new[P[k],j]\n",
    "        \n",
    "    return A_new,P\n",
    "\n",
    "#This function uses the permutation vector to give the returned A from myLu(A)\n",
    "#the right order. \n",
    "def PA(P,A):\n",
    "    a=np.copy(A)\n",
    "    n=a.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            a[i,j]=A[P[i],j]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLuTest(A):\n",
    "    A_lu , P_lu = myLu(A)\n",
    "    a=PA(P_lu,A_lu)\n",
    "    lu,p =scipy.linalg.lu_factor(A)\n",
    "    for i in range(A.shape[0]):    \n",
    "        for j in range(A.shape[0]):\n",
    "            if(round(float(a[i,j]),5)!= round(float(lu[i,j]),5)):\n",
    "                print(\"The matrices are not the same...\\n\")\n",
    "                return\n",
    "    print(\"The matrices are the same, myLu works as it should.\\n\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with full rank:\n",
      "The matrices are the same, myLu works as it should.\n",
      "\n",
      "Testing with a repeated column: \n",
      "The matrices are not the same...\n",
      "\n",
      "It seems as if myLu does not work for matrices without full rank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruker\\Documents\\anaconda32\\lib\\site-packages\\ipykernel_launcher.py:4: LinAlgWarning: Diagonal number 4 is exactly zero. Singular matrix.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[2, 5, 8, 7], [5, 2, 2, 8], [7, 5, 6, 6], [5, 4, 4, 8],],dtype=float)\n",
    "test2=np.array([[3,2,1,4],[5,3,2,1],[3,2,1,4],[1,1,2,3]])\n",
    "\n",
    "print(\"Testing with full rank:\")\n",
    "myLuTest(test)\n",
    "\n",
    "print(\"Testing with a repeated column: \")\n",
    "myLuTest(test2)\n",
    "\n",
    "print(\"It seems as if myLu does not work for matrices without full rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "1. Implement a\n",
    "\n",
    "  `def forward_substitution(A,b):`\n",
    "    \n",
    "  function that takes a lower triangular matrix `A` and some vector `b` to solve $A\\mathbf{x} = \\mathbf{b}$\n",
    "\n",
    "2. Implement a\n",
    "\n",
    "  `def backward_substitution(A,b):` \n",
    "        \n",
    "  function that takes an upper triangualr matrix `A` and some vector `b` to solve $A\\mathbf{x} = \\mathbf{b}$ for this case.\n",
    "  \n",
    "3. Combine the last two parts with Problem 2 and implement a function\n",
    "\n",
    "   `def my_solve(A,b):`\n",
    "\n",
    "   for a square matrix `A` and a right hand side `b` that computes the LU decomposition of `A` and then uses the first two parts of this problem to compute the solution to $A\\mathbf{x} = \\mathbf{b}$\n",
    "   \n",
    "4. Performance. Let's compare our implementation for two cases as well as to the original. To be precise\n",
    "  * fix some $n$, say `n=100`\n",
    "  * generate a reguar square matrix `A` (Hint: maybe create `L` and `U` here to be sure `A` is regular)\n",
    "  * generate `m`, say `m=200` right hand sides `b_k`\n",
    "  * run an experiment where you time\n",
    "\n",
    "      a) calling `m` times `my_solve(A,b)` once for each `b_k`\n",
    "\n",
    "      b) only computing the LU decomposition once and use backward and forward substitutions `m` times\n",
    "\n",
    "      c) using `np.linalg.solve`\n",
    "      \n",
    "    Where do the time differences from a) to b) come from and where the ones from c) to b)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardSubstitution(A,b): #A lower triangular\n",
    "    n=A.shape[0]\n",
    "    x=np.zeros(n) #solution vector\n",
    "    x[0]=b[0]/A[0,0]\n",
    "    for i in range(1,n):\n",
    "        sum=0\n",
    "        for j in range(0,i):\n",
    "            sum += (A[i,j]*x[j])\n",
    "        x[i]=1/A[i,i] * (b[i]-sum)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardSubstitution(A,b): #A upper triangular\n",
    "    n=A.shape[0]\n",
    "    x=np.zeros(n)\n",
    "    x[n-1]=b[n-1]/A[n-1,n-1]\n",
    "    for i in range(n-1,-1,-1):\n",
    "        sum = 0\n",
    "        for j in range(i+1,n):\n",
    "            sum += (A[i,j]*x[j])\n",
    "            x[i]=1/A[i,i] * (b[i]-sum)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_solve(A,b):\n",
    "    A_lu,P_lu=myLu(A)\n",
    "    a=PA(P_lu,A_lu) #rearrange A_lu\n",
    "    l=np.copy(A)\n",
    "    u=np.copy(A)\n",
    "    n=A.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j:\n",
    "                l[i,j]=1\n",
    "                u[i,j]=a[i,j]\n",
    "            elif i<j:    #Opposite of what it says, but this gives the right matrices (?)\n",
    "                l[i,j] = 0\n",
    "                u[i,j] = a[i,j]\n",
    "            else: \n",
    "                l[i,j]=a[i,j]\n",
    "                u[i,j]=0\n",
    "    y=forwardSubstitution(l,b[P_lu]) #b needs to be pivoted too\n",
    "    x=backwardSubstitution(u,y)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06185567  1.70103093 -0.70103093 -0.28865979]\n",
      "[ 0.06185567  1.70103093 -0.70103093 -0.28865979]\n"
     ]
    }
   ],
   "source": [
    "b=np.array([1,0,3,2])\n",
    "x= my_solve(test,b)\n",
    "print(x)\n",
    "xrett=scipy.linalg.solve(test,b)\n",
    "print(xrett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) my_solve m times:\n",
      "--- 0.26519179344177246 seconds ---\n",
      "b) my solve m times, but LU only once:\n",
      "--- 0.10348391532897949 seconds ---\n",
      "c) Linalg_solve m times:\n",
      "--- 0.07019948959350586 seconds ---\n",
      "______________________\n",
      "The time difference from a to b comes from not having to compute the LU-factorization more than once. \n",
      "The time difference from b to c is much smaller, I suppose linalg.solve also only compute LU-factorization once,\n",
      "and also have much better optimalisation in the code.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "random.seed(time.time())\n",
    "\n",
    "n=100\n",
    "m=1000\n",
    "matrix = np.array([[4,2,5,1],[1,5,6,6],[9,3,3,4],[1,1,1,4]])\n",
    "b=np.arange(matrix.shape[0])\n",
    "\n",
    "def random_b():\n",
    "    for i in range(matrix.shape[0]):\n",
    "        b[i]=random.randint(1,10)\n",
    "    return b\n",
    "def my_solve_m(m,matrix):\n",
    "    for i in range(m):\n",
    "        b=random_b()\n",
    "        x=my_solve(matrix,b)\n",
    "\n",
    "def my_solve2(n,l,u,P_lu):\n",
    "    b=random_b()\n",
    "    y=forwardSubstitution(l,b[P_lu]) \n",
    "    x=backwardSubstitution(u,y)\n",
    "    return x\n",
    "\n",
    "def my_solve2_m(m,matrix):\n",
    "    A_lu,P_lu=myLu(matrix)\n",
    "    a=PA(P_lu,A_lu) \n",
    "    l=np.copy(matrix)\n",
    "    u=np.copy(matrix)\n",
    "    n=A.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i==j:\n",
    "                l[i,j]=1\n",
    "                u[i,j]=a[i,j]\n",
    "            elif i<j:    \n",
    "                l[i,j] = 0\n",
    "                u[i,j] = a[i,j]\n",
    "            else: \n",
    "                l[i,j]=a[i,j]\n",
    "                u[i,j]=0\n",
    "    for i in range(m):\n",
    "        b=random_b()\n",
    "        x=my_solve2(n,l,u,P_lu)\n",
    "        \n",
    "def linalg_solve_m(m,matrix):\n",
    "    for i in range(m):\n",
    "        b=random_b()\n",
    "        x=scipy.linalg.solve(matrix,b)\n",
    "\n",
    "print(\"a) my_solve m times:\")        \n",
    "start_time1 = time.time()\n",
    "my_solve_m(m,matrix)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time1))\n",
    "\n",
    "print(\"b) my solve m times, but LU only once:\")\n",
    "start_time2 = time.time()\n",
    "my_solve2_m(m,matrix)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time2))\n",
    "\n",
    "print(\"c) Linalg_solve m times:\")\n",
    "start_time3 = time.time()\n",
    "linalg_solve_m(m,matrix)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time3))\n",
    "\n",
    "print(\"______________________\")\n",
    "print(\"The time difference from a to b comes from not having to compute the LU-factorization more than once. \")\n",
    "print(\"The time difference from b to c is much smaller, I suppose linalg.solve also only compute LU-factorization once,\")\n",
    "print(\"and also have much better optimalisation in the code.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
